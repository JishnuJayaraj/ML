{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keyword.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1sUQ_NLueK_p8Ysf7F3C2ohrSwYDc3nOx",
      "authorship_tag": "ABX9TyPKB5jOknvo5k4gUdWZc3zu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JishnuJayaraj/ML/blob/master/ML/NLP/KeywordExtraction/keyword.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LR4MJpR-pphp"
      },
      "source": [
        "import pandas as pd  \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np \n",
        "import spacy\n",
        "import gensim\n",
        "# !matplotlib inline\n",
        "\n",
        "import nltk\n",
        "import string\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "# Load English tokenizer, tagger, parser, NER and word vectors\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "#stopwords=nltk.download('stopwords')                  #<-----\n",
        "#punctuations = string.punctuation\n",
        "stopwords = spacy.lang.en.stop_words.STOP_WORDS"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucCG-1YBqKBS",
        "outputId": "edc9b664-2a14-4ecc-dc38-22606e083b93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "# Read data from json file\n",
        "df = pd.read_json('/content/drive/My Drive/RokinData/ToBeCleaned.json.gz')\n",
        "df = df.head(20)\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>all</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A Phased Roll Out with Big Bang Elements: Oppo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Democratizing Change Review with ThingWorx Nav...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PLM: Poorly Digitized Labs Give Dassault Systè...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Is Siemens’ New Low-Code Platform Mendix an “A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How to Converge on One PLM System—The Tough Ap...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 all\n",
              "0  A Phased Roll Out with Big Bang Elements: Oppo...\n",
              "1  Democratizing Change Review with ThingWorx Nav...\n",
              "2  PLM: Poorly Digitized Labs Give Dassault Systè...\n",
              "3  Is Siemens’ New Low-Code Platform Mendix an “A...\n",
              "4  How to Converge on One PLM System—The Tough Ap..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1lduH1RpD3w"
      },
      "source": [
        "# join heading and text column to single column\n",
        "df.columns = ['date','heading','text','link','empty']\n",
        "df['all']= df['heading'] + df['text']\n",
        "\n",
        "df = df.drop(['date','heading','text','link','empty'], axis=1 )\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqZUqttiqeaT",
        "outputId": "cda63f99-786e-4258-c978-799e8203a778",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "source": [
        "df['processed'] = df['all'].apply(lambda x: nlp(x))\n",
        "\n",
        "def is_token_allowed(token):\n",
        "     '''\n",
        "         Only allow valid tokens which are not stop words\n",
        "         and punctuation symbols.\n",
        "     '''\n",
        "     if (not token or not token.string.strip() or\n",
        "         token.is_stop or token.is_punct):\n",
        "         return False\n",
        "     return True\n",
        "\n",
        "def preprocess_token(token):\n",
        "     # Reduce token to its lowercase lemma form\n",
        "     return token.lemma_.strip().lower()\n",
        "\n",
        "\n",
        "def cleaning(row):\n",
        "  #print(d)\n",
        "  \n",
        "  doc = df['processed'].values[0]\n",
        "  #doc = row['processed']         #  <-------------------------------- WHY\n",
        "\n",
        "  #for word in doc:#\n",
        "  filtered_tokens = [preprocess_token(token)\n",
        "       for token in doc if is_token_allowed(token)]\n",
        "  return filtered_tokens\n",
        "\n",
        "\n",
        "# df['cleaned'] = df['all'].applymap(lambda x: cleaning(x) )\n",
        "df['cleaned'] = df['processed'].apply(cleaning) #, also try to use map for efficiency\n",
        "\n",
        "# Rejoining meaningful-stemmed to single snetence\n",
        "def rejoin_words(row):\n",
        "    my_list = row['cleaned']\n",
        "    joined_words = ( \" \".join(my_list))\n",
        "    return joined_words\n",
        "\n",
        "df['rejoined'] = df.apply(rejoin_words, axis=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------------\n",
        "# capitalization\n",
        "##df['all'] = df['all'].str.lower()\n",
        "# Tokenize the column\n",
        "##df['tokenized'] = df['all'].apply(lambda x: nlp(x))\n",
        "\n",
        "\n",
        "\n",
        "df.head()\n",
        "%whos"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Variable           Type         Data/Info\n",
            "-----------------------------------------\n",
            "Counter            type         <class 'collections.Counter'>\n",
            "cleaning           function     <function cleaning at 0x7f1c1b0b0950>\n",
            "df                 DataFrame                             <...>\\n\\n[20 rows x 4 columns]\n",
            "gensim             module       <module 'gensim' from '/u<...>ages/gensim/__init__.py'>\n",
            "is_token_allowed   function     <function is_token_allowed at 0x7f1c13819ae8>\n",
            "nlp                English      <spacy.lang.en.English object at 0x7f1c1b15af28>\n",
            "nltk               module       <module 'nltk' from '/usr<...>ckages/nltk/__init__.py'>\n",
            "np                 module       <module 'numpy' from '/us<...>kages/numpy/__init__.py'>\n",
            "pd                 module       <module 'pandas' from '/u<...>ages/pandas/__init__.py'>\n",
            "plt                module       <module 'matplotlib.pyplo<...>es/matplotlib/pyplot.py'>\n",
            "preprocess_token   function     <function preprocess_token at 0x7f1c226218c8>\n",
            "re                 module       <module 're' from '/usr/lib/python3.6/re.py'>\n",
            "rejoin_words       function     <function rejoin_words at 0x7f1c1a335e18>\n",
            "spacy              module       <module 'spacy' from '/us<...>kages/spacy/__init__.py'>\n",
            "stopwords          set          {'third', 'every', 'each'<...>'within', 'done', 'does'}\n",
            "string             module       <module 'string' from '/u<...>lib/python3.6/string.py'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-VPi3l7bae5",
        "outputId": "b15cb4b0-c23c-4b12-b73f-b739cc832224",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "freq_words = []\n",
        "# Iterate through rows\n",
        "for index, row in df.iterrows():\n",
        "    text = row['cleaned']\n",
        "    word_freq = Counter(text)\n",
        "    freq_words.append(word_freq.most_common(5))\n",
        "\n",
        "print(freq_words[1])\n",
        "\n",
        "## ------------------------END ------------------------------"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('scania', 39), ('project', 25), ('dassault', 24), ('malmberg', 24), ('plm', 20)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waiBG8bJyaNs"
      },
      "source": [
        "## Word Embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSgaC-6lrjEG",
        "outputId": "fccf4b5c-bf34-488a-b951-5c216c67032a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        }
      },
      "source": [
        "# Entity recognition\n",
        "# df['new_col'] = df[2].apply(lambda x: list(nlp(x).ents))\n",
        "#for entity in mydoc.ents:\n",
        "  #print(entity.label_, ' | ', entity.text)\n",
        "\n",
        "# df.head()\n",
        "# POS tagging\n",
        "#for token in doc:\n",
        "    #print(token.text, token.pos_, token.tag_)\n",
        "\n",
        "# NER tagging\n",
        "#for token in doc:\n",
        "    #print(token.text, token.ent_type_)\n",
        "\n",
        "example_content = df.iloc[1]\n",
        "print(example_content['tokenized'])\n",
        "\n",
        "df.head()\n",
        "\n",
        "print(string.punctuation)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kirigami designs hold thousands of times their own weightthe japanese art of origami (from ori, folding, and kami, paper) transforms flat sheets of paper into complex sculptures. variations include kirigami (from kiri, to cut), a version of origami that allows materials to be cut and reconnected using tape or glue.\n",
            "but while both art forms are a source of ideas for science, architecture, and design, each has fundamental limitations. the flat folds required by origami result in an unlockable overall structure, while kirigami creations can't be unfolded back into their original, flattened states because of the adhesive.\n",
            "taking inspiration from both art forms, researchers describe a new set of motifs for creating lightweight, strong, and foldable structures using soft materials. these kirigami structures can support 14,000 times their weight and, because they don't require adhesives or fasteners, can easily be flattened and refolded. published in physical review x, the work was conducted by visiting graduate student xinyu wang and professor randall kamien of the university of pennsylvania in collaboration with simon guest from the university of cambridge.\n",
            "wang, a ph.d. student at southeast university, was interested in studying the mechanical properties of origami and kirigami structures and reached out to kamien to start a new collaboration. after wang arrived at the kamien lab in september 2018, kamien asked her to try some new designs using his group's set of rules for exploring kirigami structures.\n",
            "shortly thereafter, wang showed kamien a new design for a kirigami triangle that had tilted walls. kamien was initially surprised to see that wang had left the excess flaps from the cuts in place. \"the usual kirigami route is to cut that off and tape it,\" says kamien. wang \"found that, in this particular geometry, you can get the flaps to fit.\"\n",
            "while a single triangle wasn't particularly strong on its own, the researchers noticed that when several were arranged in a repetitive design, the force they could support was much greater than expected. \"here was this structure that didn't require tape, it had cuts, and it was really strong,\" kamien says. \"suddenly, we have this system that we hadn't anticipated at all.\"\n",
            "to figure out what made this geometry so resilient, wang made several versions of different \"soft\" materials, including paper, copper, and plastic. she also made versions where the cut flaps were taped, cut, or damaged. using industry-grade tension and compression testing equipment at the laboratory for research on the structure of matter, the scientists found that the geometric structure could support 14,000 times its own weight. the tilted, triangular design was strongest when the flaps were undamaged and untapped, and it was also stronger than the same design with vertical walls.\n",
            "with the help of guest, the researchers realized that two deviations from the group's typical kirigami rules were key to the structure's strength. when the walls of the triangles are angled, any force applied to the top can be translated into horizontal compression within the center of the design. \"with the vertical ones, there's no way to turn a downward force into a sideways force without bending the paper,\" says kamien. they also found that the paper-to-paper overlap from leaving the cut flaps in place allowed the triangles to press up against their neighbors, which helped distribute the vertical load.\n",
            "this paper is yet another example of how kirigami can be used as a \"tool\" for scientists and engineers, this time for creating strong, rigid objects out of soft materials. \"we figured out how to use materials that can bend and stretch, and we can actually strengthen these materials,\" says wang. one possible application could be to make inexpensive, lightweight, and deployable structures, such as temporary shelter tents that are strong and durable but can also be easily assembled and disassembled.\n",
            "kamien also pictures this interleaved kirigami extension assembly as a way to create furniture in the future. \"someday, you'll go to ikea, you fold the box into the furniture, and the only thing inside is the cushion. you don't need any of those connectors or little screws,\" says kamien.\n",
            "thanks to wang's \"inspired\" design and kamien's burgeoning collaboration with wang and her advisors jianguo cai and jian feng , the possibilities for future ideas and designs are endless. \"there were things about this study that are totally outside the scope of what a physicist would know,\" says kamien. \"it was this perfect blend of what i could do and what she could do.\"\n",
            "provided by university of pennsylvania\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-6b358b06b2aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'string' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyYQf4HJlleR"
      },
      "source": [
        "complete_text = ('Gus Proto is a Python developer currently'\n",
        "     'working for a London-based Fintech company. He is'\n",
        "    ' interested in learning Natural Language Processing.'\n",
        "     ' There is a developer conference happening on 21 July'\n",
        "     ' 2019 in London. It is titled \"Applications of Natural'\n",
        "     ' Language Processing\". There is a helpline number '\n",
        "     ' available at +1-1234567891. Gus is helping organize it.'\n",
        "    ' He keeps organizing local Python meetups and several'\n",
        "     ' internal talks at his workplace. Gus is also presenting'\n",
        "     ' a talk. The talk will introduce the reader about \"Use'\n",
        "    ' cases of Natural Language Processing in Fintech\".'\n",
        "     ' Apart from his work, he is very passionate about music.'\n",
        "    ' Gus is learning to play the Piano. He has enrolled '\n",
        "     ' himself in the weekend batch of Great Piano Academy.'\n",
        "    ' Great Piano Academy is situated in Mayfair or the City'\n",
        "    ' of London and has world-class piano instructors.')\n",
        "\n",
        "complete_doc = nlp(complete_text)\n",
        "\n",
        "# Remove stop words and punctuation symbols\n",
        "words = [token.text for token in complete_doc\n",
        "if not token.is_stop and not token.is_punct] \n",
        "\n",
        "word_freq = Counter(words)\n",
        "# 5 commonly occurring words with their frequencies\n",
        "common_words = word_freq.most_common(5)\n",
        "print (common_words)\n",
        "\n",
        "# Unique words\n",
        "unique_words = [word for (word, freq) in word_freq.items() if freq == 1]\n",
        "print (unique_words)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}